{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":196262,"sourceType":"datasetVersion","datasetId":84803}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Installations and Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T12:43:17.929564Z","iopub.execute_input":"2025-03-18T12:43:17.929855Z","iopub.status.idle":"2025-03-18T12:43:20.844808Z","shell.execute_reply.started":"2025-03-18T12:43:17.929829Z","shell.execute_reply":"2025-03-18T12:43:20.843636Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"print(f\"Numpy version: {np.__version__}\")\nprint(f\"Pandas version: {pd.__version__}\")\nprint(f\"Sklearn version: {sklearn.__version__}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T12:43:20.846673Z","iopub.execute_input":"2025-03-18T12:43:20.847153Z","iopub.status.idle":"2025-03-18T12:43:20.854015Z","shell.execute_reply.started":"2025-03-18T12:43:20.847092Z","shell.execute_reply":"2025-03-18T12:43:20.852774Z"}},"outputs":[{"name":"stdout","text":"Numpy version: 1.26.4\nPandas version: 2.2.3\nSklearn version: 1.2.2\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Dataset Creation","metadata":{}},{"cell_type":"code","source":"DATA_DIR = \"/kaggle/input/bank-note-authentication-uci-data/BankNote_Authentication.csv\"\ndata = pd.read_csv(DATA_DIR)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T12:43:20.855836Z","iopub.execute_input":"2025-03-18T12:43:20.856305Z","iopub.status.idle":"2025-03-18T12:43:20.897945Z","shell.execute_reply.started":"2025-03-18T12:43:20.856266Z","shell.execute_reply":"2025-03-18T12:43:20.896689Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# checking the data\ndata.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T12:43:20.899163Z","iopub.execute_input":"2025-03-18T12:43:20.899585Z","iopub.status.idle":"2025-03-18T12:43:20.932899Z","shell.execute_reply.started":"2025-03-18T12:43:20.899526Z","shell.execute_reply":"2025-03-18T12:43:20.931640Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1372 entries, 0 to 1371\nData columns (total 5 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   variance  1372 non-null   float64\n 1   skewness  1372 non-null   float64\n 2   curtosis  1372 non-null   float64\n 3   entropy   1372 non-null   float64\n 4   class     1372 non-null   int64  \ndtypes: float64(4), int64(1)\nmemory usage: 53.7 KB\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T12:43:20.933998Z","iopub.execute_input":"2025-03-18T12:43:20.934404Z","iopub.status.idle":"2025-03-18T12:43:20.968886Z","shell.execute_reply.started":"2025-03-18T12:43:20.934369Z","shell.execute_reply":"2025-03-18T12:43:20.967643Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   variance  skewness  curtosis  entropy  class\n0   3.62160    8.6661   -2.8073 -0.44699      0\n1   4.54590    8.1674   -2.4586 -1.46210      0\n2   3.86600   -2.6383    1.9242  0.10645      0\n3   3.45660    9.5228   -4.0112 -3.59440      0\n4   0.32924   -4.4552    4.5718 -0.98880      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>variance</th>\n      <th>skewness</th>\n      <th>curtosis</th>\n      <th>entropy</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.62160</td>\n      <td>8.6661</td>\n      <td>-2.8073</td>\n      <td>-0.44699</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.54590</td>\n      <td>8.1674</td>\n      <td>-2.4586</td>\n      <td>-1.46210</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.86600</td>\n      <td>-2.6383</td>\n      <td>1.9242</td>\n      <td>0.10645</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.45660</td>\n      <td>9.5228</td>\n      <td>-4.0112</td>\n      <td>-3.59440</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.32924</td>\n      <td>-4.4552</td>\n      <td>4.5718</td>\n      <td>-0.98880</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# splitting features and classes\nX, y = data.iloc[:, :-1], data.iloc[:, -1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T12:43:20.972478Z","iopub.execute_input":"2025-03-18T12:43:20.972913Z","iopub.status.idle":"2025-03-18T12:43:20.980925Z","shell.execute_reply.started":"2025-03-18T12:43:20.972871Z","shell.execute_reply":"2025-03-18T12:43:20.979544Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# converting data into numpy arrays for comptational reasons\nX = X.to_numpy()\ny = y.to_numpy().reshape(-1, 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T12:43:20.983217Z","iopub.execute_input":"2025-03-18T12:43:20.983618Z","iopub.status.idle":"2025-03-18T12:43:21.001644Z","shell.execute_reply.started":"2025-03-18T12:43:20.983585Z","shell.execute_reply":"2025-03-18T12:43:21.000308Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# splitting data to train and test\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=42, stratify=y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T12:43:21.002888Z","iopub.execute_input":"2025-03-18T12:43:21.003363Z","iopub.status.idle":"2025-03-18T12:43:21.032413Z","shell.execute_reply.started":"2025-03-18T12:43:21.003319Z","shell.execute_reply":"2025-03-18T12:43:21.030992Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## Define Network Structure","metadata":{}},{"cell_type":"code","source":"class TwoLayerPerceptron():\n    def __init__(self, X_train, y_train, n_hidden, n_y, lr, activation_fn):\n        self.X_train = X_train\n        self.y_train = y_train\n        self.n_feature = X_train.shape[1]\n        self.n_hidden = n_hidden\n        self.n_y = n_y\n        self.params = {}\n        self.cache = {}\n        self.grads = {}\n        self.lr = lr\n        self.activation_fn = activation_fn\n\n    def initialize_params(self):\n        np.random.seed(42)\n        W1 = np.random.randn(self.n_hidden, self.n_feature) * 0.01\n        b1 = np.zeros((self.n_hidden, 1))\n        W2 = np.random.randn(self.n_y, self.n_hidden) * 0.01\n        b2 = np.zeros((self.n_y, 1))\n\n        self.params = {\n            \"W1\" : W1,\n            \"b1\" : b1,\n            \"W2\" : W2,\n            \"b2\" : b2\n        }\n        return self.params\n\n    def forward(self, X):\n        W1 = self.params[\"W1\"]\n        b1 = self.params[\"b1\"]\n        W2 = self.params[\"W2\"]\n        b2 = self.params[\"b2\"]\n\n        Z1 = np.dot(W1, X.T) + b1\n        if (self.activation_fn == \"tanh\"):\n            A1 = np.tanh(Z1)\n        elif (self.activation_fn == \"RELU\"):\n            A1 = self.RELU(Z1)\n            A1 = np.clip(A1, -0.9999, 0.9999)  \n        else:\n            print(\"Please write a valid activation function!\")\n        Z2 = np.dot(W2, A1) + b2\n        A2 = self.sigmoid(Z2)\n        A2 = np.clip(A2, 1e-10, 1 - 1e-10)\n\n        self.cache = {\n            \"Z1\" : Z1,\n            \"A1\" : A1,\n            \"Z2\" : Z2,\n            \"A2\" : A2,\n        }\n        return A2, self.cache\n\n    def loss(self):\n        A2 = self.cache[\"A2\"]\n        m = A2.shape[1]\n        Y = self.y_train\n        loss = - (np.dot(np.log(A2), Y) + np.dot(np.log(1 - A2), (1 - Y))) / m\n        loss = float(np.squeeze(loss))\n        return loss\n\n    def backward(self):\n        X = self.X_train\n        y = self.y_train\n        m = X.shape[0]\n        W1 = self.params[\"W1\"]\n        W2 = self.params[\"W2\"]\n        A1 = self.cache[\"A1\"]\n        A2 = self.cache[\"A2\"]\n\n        dZ2 = A2.T - y \n        dW2 = np.dot(dZ2.T, A1.T) / m \n        db2 = np.sum(dZ2, axis=0, keepdims=True) / m \n        dZ1 = np.dot(dZ2, W2) * (1 - np.power(A1, 2)).T \n        dW1 = np.dot(dZ1.T, X) / m \n        db1 = np.sum(dZ1, axis=0, keepdims=True) / m \n        \n        self.grads = {\n            \"dW1\" : dW1,\n            \"dW2\" : dW2,\n            \"db1\" : db1,\n            \"db2\" : db2\n        }\n\n        return self.grads\n\n    def update_params(self):\n        lr = self.lr\n        W1 = self.params[\"W1\"]\n        b1 = self.params[\"b1\"]\n        W2 = self.params[\"W2\"]\n        b2 = self.params[\"b2\"]\n\n        dW1 = self.grads[\"dW1\"]\n        db1 = self.grads[\"db1\"]\n        dW2 = self.grads[\"dW2\"]\n        db2 = self.grads[\"db2\"]\n\n        self.params[\"W1\"] -= self.lr * self.grads[\"dW1\"]\n        self.params[\"b1\"] -= self.lr * self.grads[\"db1\"].T\n        self.params[\"W2\"] -= self.lr * self.grads[\"dW2\"]\n        self.params[\"b2\"] -= self.lr * self.grads[\"db2\"]\n\n        return self.params\n\n    def train(self, num_steps, print_cost=True):\n        self.initialize_params()\n        X = self.X_train\n\n        for i in range(num_steps):\n            A2, cache = self.forward(X)\n            loss = self.loss()\n            grads = self.backward()\n            self.update_params()\n\n            if (loss < 0.20):\n                print(f\"Loss at iteration {i} is {loss:.6f}\")\n                return\n\n            if (print_cost and i % 500 == 0):\n                print(f\"Loss at iteration {i} is {loss:.6f}\")\n        print(f\"The model could not exceed the 0.2 threshold.\")\n        print(f\"Loss at iteration {i} is {loss:.6f}\")\n\n    def predict(self, X_test):\n        params = self.params\n        A2, cache = self.forward(X_test)\n        preds = A2 > 0.5\n        return preds\n    \n    # helper functions\n    def sigmoid(self, Z):\n        Z = np.clip(Z, -500, 500) \n        return 1 / (1 + np.exp(-Z))\n\n    def RELU(self, x):\n        x = np.nan_to_num(x) \n        return np.maximum(0, x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T12:43:21.033855Z","iopub.execute_input":"2025-03-18T12:43:21.034314Z","iopub.status.idle":"2025-03-18T12:43:21.064293Z","shell.execute_reply.started":"2025-03-18T12:43:21.034266Z","shell.execute_reply":"2025-03-18T12:43:21.062936Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## Training the Models","metadata":{}},{"cell_type":"code","source":"num_hidden = 5\nnum_y = 1\nlr = 1e-2\nMLP_tanh = TwoLayerPerceptron(X_train, y_train, num_hidden, num_y, lr, activation_fn=\"tanh\")\nMLP_RELU = TwoLayerPerceptron(X_train, y_train, num_hidden, num_y, lr, activation_fn=\"RELU\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T12:43:21.065430Z","iopub.execute_input":"2025-03-18T12:43:21.065858Z","iopub.status.idle":"2025-03-18T12:43:21.088094Z","shell.execute_reply.started":"2025-03-18T12:43:21.065814Z","shell.execute_reply":"2025-03-18T12:43:21.086587Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"num_steps = 5000\nMLP_tanh.train(num_steps)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T12:43:21.089526Z","iopub.execute_input":"2025-03-18T12:43:21.090013Z","iopub.status.idle":"2025-03-18T12:43:21.689215Z","shell.execute_reply.started":"2025-03-18T12:43:21.089973Z","shell.execute_reply":"2025-03-18T12:43:21.687820Z"}},"outputs":[{"name":"stdout","text":"Loss at iteration 0 is 0.693481\nLoss at iteration 500 is 0.293852\nLoss at iteration 643 is 0.199625\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"num_steps = 10000\nMLP_RELU.train(num_steps)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T12:43:21.690356Z","iopub.execute_input":"2025-03-18T12:43:21.690721Z","iopub.status.idle":"2025-03-18T12:43:27.758909Z","shell.execute_reply.started":"2025-03-18T12:43:21.690691Z","shell.execute_reply":"2025-03-18T12:43:27.757851Z"}},"outputs":[{"name":"stdout","text":"Loss at iteration 0 is 0.693206\nLoss at iteration 500 is 0.547947\nLoss at iteration 1000 is 0.387134\nLoss at iteration 1500 is 0.324073\nLoss at iteration 2000 is 0.291502\nLoss at iteration 2500 is 0.273908\nLoss at iteration 3000 is 0.263561\nLoss at iteration 3500 is 0.256947\nLoss at iteration 4000 is 0.251553\nLoss at iteration 4500 is 0.246964\nLoss at iteration 5000 is 0.242369\nLoss at iteration 5500 is 0.238739\nLoss at iteration 6000 is 0.235589\nLoss at iteration 6500 is 0.232700\nLoss at iteration 7000 is 0.230127\nLoss at iteration 7500 is 0.228054\nLoss at iteration 8000 is 0.226135\nLoss at iteration 8500 is 0.224728\nLoss at iteration 9000 is 0.223684\nLoss at iteration 9500 is 0.222556\nThe model could not exceed the 0.2 threshold.\nLoss at iteration 9999 is 0.221672\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"tanh_preds = MLP_tanh.predict(X_test)\nRELU_preds = MLP_RELU.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T12:43:27.759951Z","iopub.execute_input":"2025-03-18T12:43:27.760387Z","iopub.status.idle":"2025-03-18T12:43:27.766235Z","shell.execute_reply.started":"2025-03-18T12:43:27.760349Z","shell.execute_reply":"2025-03-18T12:43:27.765014Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Testing the Models","metadata":{}},{"cell_type":"code","source":"def print_metrics(y_test, y_pred):\n    y_test = y_test.flatten()\n    y_pred = y_pred.flatten()\n\n    acc = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred, average=\"binary\")\n    recall = recall_score(y_test, y_pred, average=\"binary\")\n    f1 = f1_score(y_test, y_pred, average=\"binary\")\n    conf_mx = confusion_matrix(y_test, y_pred)\n\n    print(f\"Accuracy: {acc:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1 Score: {f1:.4f}\")\n    print(\"\\nConfusion Matrix:\")\n    print(conf_mx)\n    print(\"\\nClassification Report:\")\n    print(classification_report(y_test, y_pred)) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T12:43:27.767090Z","iopub.execute_input":"2025-03-18T12:43:27.767572Z","iopub.status.idle":"2025-03-18T12:43:27.790640Z","shell.execute_reply.started":"2025-03-18T12:43:27.767542Z","shell.execute_reply":"2025-03-18T12:43:27.789445Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"print_metrics(y_test, tanh_preds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T12:43:27.791816Z","iopub.execute_input":"2025-03-18T12:43:27.792211Z","iopub.status.idle":"2025-03-18T12:43:27.829572Z","shell.execute_reply.started":"2025-03-18T12:43:27.792169Z","shell.execute_reply":"2025-03-18T12:43:27.828389Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.9673\nPrecision: 0.9669\nRecall: 0.9590\nF1 Score: 0.9630\n\nConfusion Matrix:\n[[149   4]\n [  5 117]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.97      0.97      0.97       153\n           1       0.97      0.96      0.96       122\n\n    accuracy                           0.97       275\n   macro avg       0.97      0.97      0.97       275\nweighted avg       0.97      0.97      0.97       275\n\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"print_metrics(y_test, RELU_preds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T12:43:27.830696Z","iopub.execute_input":"2025-03-18T12:43:27.831089Z","iopub.status.idle":"2025-03-18T12:43:27.852106Z","shell.execute_reply.started":"2025-03-18T12:43:27.831046Z","shell.execute_reply":"2025-03-18T12:43:27.850843Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.9309\nPrecision: 0.9120\nRecall: 0.9344\nF1 Score: 0.9231\n\nConfusion Matrix:\n[[142  11]\n [  8 114]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.95      0.93      0.94       153\n           1       0.91      0.93      0.92       122\n\n    accuracy                           0.93       275\n   macro avg       0.93      0.93      0.93       275\nweighted avg       0.93      0.93      0.93       275\n\n","output_type":"stream"}],"execution_count":16}]}